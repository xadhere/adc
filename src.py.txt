#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‘è“æ´¾æ™ºèƒ½è·Ÿéš - ç»¼åˆä¼˜åŒ–ç‰ˆï¼ˆå¸¦è“ç‰™æ‰‹æœºæ§åˆ¶ + æŠ¥è­¦åŠŸèƒ½ï¼‰
ç‰¹ç‚¹ï¼š
- æ‘„åƒå¤´æ›å…‰ä¼˜åŒ–ï¼ˆé¿å…è¿‡æ›ï¼Œæå‡æš—éƒ¨ï¼‰
- ç›®æ ‡ä¸¢å¤±ç«‹å³åœæ­¢ï¼ˆæ— è™šçº¿ï¼‰
- å¯é€‰å›¾åƒé¢„å¤„ç†å¢å¼ºï¼ˆCLAHE/ä¼½é©¬æ ¡æ­£ï¼‰
- ä¿ç•™å¤šç›®æ ‡è·Ÿè¸ªã€æ¯”ä¾‹è½¬å‘ã€Flaskæ˜¾ç¤º
- è“ç‰™æ‰‹æœºæ§åˆ¶ï¼šæ¨¡å¼åˆ‡æ¢ã€æ‰‹åŠ¨æŒ‡ä»¤ã€ç”µé‡æŸ¥è¯¢
- æŠ¥è­¦åŠŸèƒ½ï¼šæ‰‹åŠ¨è¶…æ—¶ã€è¶…å£°æ³¢éšœç¢ç‰©æ¥è¿‘
"""

from flask import Flask, Response, render_template_string
import cv2
import threading
import time
import serial
import numpy as np
import subprocess
import queue
from ultralytics import YOLO

# ==================== é…ç½®å‚æ•°ï¼ˆè¯·æ ¹æ®å®é™…ä¿®æ”¹ï¼‰====================
MODEL_PATH = "/home/pi/yolov8n_ncnn_model"          # NCNNæ¨¡å‹æ–‡ä»¶å¤¹
# å¦‚ä¸ä½¿ç”¨è‡ªå®šä¹‰è·Ÿè¸ªå™¨ï¼Œè¯·å°†ä¸‹ä¸€è¡Œæ³¨é‡Šæ‰
TRACKER_CFG = "/home/pi/my_bytetrack.yaml"

CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
INPUT_SIZE = 320                                    # æ¨¡å‹è¾“å…¥å°ºå¯¸
CAMERA_FPS = 30
CAMERA_BUFFERSIZE = 1

CONF_THRESH = 0.25                                   # æ£€æµ‹ç½®ä¿¡åº¦
IOU_THRESH = 0.6                                     # NMSé˜ˆå€¼
MAX_MISSED_FRAMES = 60                               # ç›®æ ‡æœ€å¤§ä¸¢å¤±å¸§æ•°

# æ¯”ä¾‹è½¬å‘å‚æ•°ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
DEAD_ZONE = 10
MAX_OFFSET = 200
MAX_DIFF = 210
BASE_SPEED = 210

# åŠ¨æ€æ¨ç†é—´éš”
FRAME_SKIP_IDLE = 5
FRAME_SKIP_TRACK = 1

# ä¸‹ä½æœºä¸²å£ï¼ˆæ§åˆ¶å°è½¦ï¼Œå¹¶æ¥æ”¶ä¼ æ„Ÿå™¨æ•°æ®ï¼‰
SERIAL_PORT = "/dev/ttyUSB0"
BAUDRATE = 9600

# è“ç‰™ä¸²å£ï¼ˆç”±ç³»ç»Ÿ rfcomm æœåŠ¡æä¾›ï¼‰
BT_SERIAL_PORT = "/dev/rfcomm0"
BT_BAUDRATE = 9600

# è§†é¢‘æµ
JPEG_QUALITY = 35
STREAM_SLEEP = 0.05

# å›¾åƒå¢å¼ºå¼€å…³ï¼ˆTrue å¯ç”¨ï¼ŒFalse ç¦ç”¨ï¼‰
ENABLE_ENHANCE = True   # å¯ç”¨åå¯æ”¹å–„ä½å…‰è¯†åˆ«ï¼Œä½†ä¼šå¢åŠ CPUè´Ÿè½½
ENHANCE_METHOD = "gamma"  # "gamma" æˆ– "clahe"
GAMMA = 1.3              # ä¼½é©¬å€¼ >1 å˜äº®
CLAHE_CLIP = 2.0         # CLAHE å¯¹æ¯”åº¦é™åˆ¶

# ==================== æ‘„åƒå¤´æ›å…‰ä¼˜åŒ–å‚æ•°ï¼ˆè‡ªåŠ¨æ¨¡å¼ï¼‰====================
CAMERA_SETTINGS = {
    "auto_exposure": 3,              # è‡ªåŠ¨æ›å…‰æ¨¡å¼ï¼ˆ3=å…‰åœˆä¼˜å…ˆï¼‰
    "backlight_compensation": 1,      # èƒŒå…‰è¡¥å¿ï¼ˆ1=å¼€å¯ï¼‰
    "brightness": 15,                 # äº®åº¦ï¼ˆé€‚å½“é™ä½ï¼Œé¿å…è¿‡æ›ï¼‰
    "contrast": 200,                  # å¯¹æ¯”åº¦ï¼ˆé€‚å½“é™ä½ï¼Œå‡å°‘é«˜å…‰ï¼‰
    "gamma": 18,                      # ä¼½é©¬å€¼ï¼ˆæ¢å¤é»˜è®¤ï¼Œé€šè¿‡è½¯ä»¶å¢å¼ºï¼‰
    "gain": 4,                        # å¢ç›Š
    "saturation": 300                  # é¥±å’Œåº¦
}

# ==================== æŠ¥è­¦å‚æ•° ====================
MANUAL_TIMEOUT_SEC = 30                 # æ‰‹åŠ¨æ¨¡å¼è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œè¶…æ—¶åè‡ªåŠ¨åˆ‡å›è‡ªåŠ¨æ¨¡å¼å¹¶æŠ¥è­¦
ULTRASONIC_ALARM_DISTANCE = 30          # è¶…å£°æ³¢æŠ¥è­¦è·ç¦»ï¼ˆå˜ç±³ï¼‰ï¼Œä½äºæ­¤å€¼è§¦å‘æŠ¥è­¦
ULTRASONIC_ALARM_COOLDOWN = 5           # è¶…å£°æ³¢æŠ¥è­¦æœ€å°é—´éš”ï¼ˆç§’ï¼‰
# ===================================================================

# ---------- æ¨¡å¼å®šä¹‰ ----------
MODE_AUTO = 1
MODE_MANUAL = 2
current_mode = MODE_AUTO   # é»˜è®¤ä¸ºè‡ªåŠ¨æ¨¡å¼

# ---------- ä¼ æ„Ÿå™¨æ•°æ® ----------
battery_voltage = None      # æœ€æ–°ä»ä¸‹ä½æœºè¯»å–çš„ç”µå‹å€¼
ultrasonic_distance = None  # æœ€æ–°ä»ä¸‹ä½æœºè¯»å–çš„è¶…å£°æ³¢è·ç¦»ï¼ˆå˜ç±³ï¼‰

# ---------- è“ç‰™å‘½ä»¤é˜Ÿåˆ— ----------
bt_cmd_queue = queue.Queue()

# ---------- æŠ¥è­¦çŠ¶æ€ ----------
last_manual_cmd_time = time.time()      # æœ€åä¸€æ¬¡æ‰‹åŠ¨æŒ‡ä»¤æ¥æ”¶æ—¶é—´
manual_timeout_alarm_triggered = False  # æ‰‹åŠ¨è¶…æ—¶æ˜¯å¦å·²æŠ¥è­¦ï¼ˆç”¨äºé˜²æ­¢é‡å¤æŠ¥è­¦ï¼‰
last_ultrasonic_alarm_time = 0          # ä¸Šæ¬¡è¶…å£°æ³¢æŠ¥è­¦æ—¶é—´ï¼ˆç§’ï¼‰

# ---------- åº”ç”¨æ‘„åƒå¤´å‚æ•° ----------
def apply_camera_settings():
    """ä½¿ç”¨v4l2-ctlè®¾ç½®æ‘„åƒå¤´å‚æ•°ï¼ˆéœ€å®‰è£…v4l-utilsï¼‰"""
    try:
        for ctrl, value in CAMERA_SETTINGS.items():
            subprocess.run(
                ["v4l2-ctl", "-d", "/dev/video0", "--set-ctrl", f"{ctrl}={value}"],
                check=False, capture_output=True
            )
        print("âœ… æ‘„åƒå¤´å‚æ•°å·²åº”ç”¨")
    except Exception as e:
        print(f"âš ï¸ æ‘„åƒå¤´å‚æ•°è®¾ç½®å¤±è´¥: {e}")

# ---------- å›¾åƒå¢å¼ºå‡½æ•° ----------
def enhance_image(img):
    """å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†å¢å¼ºï¼Œæ”¹å–„ä½å…‰è¯†åˆ«"""
    if not ENABLE_ENHANCE:
        return img
    if ENHANCE_METHOD == "gamma":
        # ä¼½é©¬æ ¡æ­£
        gamma = GAMMA
        lookup = np.array([(i / 255.0) ** (1/gamma) * 255 for i in range(256)]).astype('uint8')
        return cv2.LUT(img, lookup)
    elif ENHANCE_METHOD == "clahe":
        # CLAHE å¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=(8,8))
        l = clahe.apply(l)
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    return img

# ---------- ä¸‹ä½æœºä¸²å£ ----------
try:
    ser = serial.Serial(SERIAL_PORT, BAUDRATE, timeout=1)
    print(f"âœ… ä¸‹ä½æœºä¸²å£ {SERIAL_PORT} æ‰“å¼€æˆåŠŸ")
except Exception as e:
    print(f"âŒ ä¸‹ä½æœºä¸²å£æ‰“å¼€å¤±è´¥: {e}")
    ser = None

# ---------- è“ç‰™ä¸²å£ï¼ˆåˆå§‹å°è¯•æ‰“å¼€ï¼Œå¯èƒ½å¤±è´¥ï¼‰ ----------
bt_ser = None
try:
    bt_ser = serial.Serial(BT_SERIAL_PORT, BT_BAUDRATE, timeout=1)
    print(f"âœ… è“ç‰™ä¸²å£ {BT_SERIAL_PORT} æ‰“å¼€æˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ è“ç‰™ä¸²å£æ‰“å¼€å¤±è´¥: {e}ï¼ˆæ‰‹æœºæœªè¿æ¥æ—¶æ­£å¸¸ï¼‰")

# ---------- æ¨¡å‹ ----------
print("æ­£åœ¨åŠ è½½NCNNæ¨¡å‹...")
model = YOLO(MODEL_PATH)
print("âœ… NCNNæ¨¡å‹åŠ è½½æˆåŠŸ")

# ---------- Flask ----------
app = Flask(__name__)
frame_lock = threading.Lock()
current_frame = None
current_cmd_display = "S"

# è·Ÿè¸ªçŠ¶æ€
target_id = None
target_lost_frames = 0
last_boxes = []          # å½“å‰ç›®æ ‡æ¡†ï¼ˆç”¨äºç»˜åˆ¶å’ŒæŒ‡ä»¤ï¼‰
last_scores = []
all_boxes = []           # æ‰€æœ‰æ£€æµ‹æ¡†ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
all_scores = []
prev_target_box = None   # ä¸Šä¸€å¸§ç›®æ ‡æ¡†ï¼ˆä»…ç”¨äºç»˜åˆ¶è™šçº¿ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ä¸å†ç»˜åˆ¶ï¼‰

# ---------- å·¥å…·å‡½æ•° ----------
def send_command(cmd_str):
    """å‘ä¸‹ä½æœºå‘é€æŒ‡ä»¤"""
    if ser and ser.is_open:
        try:
            ser.write((cmd_str + '\n').encode())
        except Exception as e:
            print(f"ä¸²å£å‘é€é”™è¯¯: {e}")

def send_bt_response(msg):
    """é€šè¿‡è“ç‰™å‘æ‰‹æœºå‘é€å“åº”"""
    global bt_ser
    if bt_ser and bt_ser.is_open:
        try:
            bt_ser.write((msg + '\n').encode())
        except Exception as e:
            print(f"è“ç‰™å‘é€é”™è¯¯: {e}")

def select_target_from_boxes(boxes, confs, ids, frame_center_x):
    if len(boxes) == 0:
        return None
    centers = (boxes[:, 0] + boxes[:, 2]) / 2
    distances = np.abs(centers - frame_center_x)
    sorted_idx = np.argsort(distances)
    return ids[sorted_idx[0]]

def calculate_command(boxes, frame_center_x):
    if boxes is None or len(boxes) == 0:
        return 'S', 0
    if isinstance(boxes, np.ndarray):
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        idx = np.argmax(areas)
        largest_box = boxes[idx]
    else:
        largest_box = max(boxes, key=lambda b: (b[2] - b[0]) * (b[3] - b[1]))
    x1, y1, x2, y2 = largest_box
    person_center_x = (x1 + x2) // 2
    offset = person_center_x - frame_center_x
    if abs(offset) < DEAD_ZONE:
        return 'F', BASE_SPEED
    abs_offset = min(abs(offset), MAX_OFFSET)
    diff = int(MAX_DIFF * abs_offset / MAX_OFFSET)
    return ('L', diff) if offset < 0 else ('R', diff)

def process_bluetooth_command(cmd):
    global current_mode, CONF_THRESH, BASE_SPEED, battery_voltage
    global last_manual_cmd_time, manual_timeout_alarm_triggered
    cmd = cmd.strip()
    if not cmd:
        return

    print(f"ğŸ“± å¤„ç†è“ç‰™æŒ‡ä»¤: {cmd}")

    # ç®€åŒ–æ¨¡å¼åˆ‡æ¢ï¼š1=æ‰‹åŠ¨ï¼Œ2=è‡ªåŠ¨
    if cmd == "1":
        current_mode = MODE_MANUAL
        last_manual_cmd_time = time.time()      # <-- é‡ç½®è®¡æ—¶å™¨
        manual_timeout_alarm_triggered = False
        print("åˆ‡æ¢åˆ°æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
    elif cmd == "2":
        current_mode = MODE_AUTO
        print("åˆ‡æ¢åˆ°è‡ªåŠ¨è·Ÿéšæ¨¡å¼")
    # æ‰‹åŠ¨æ§åˆ¶æŒ‡ä»¤ï¼ˆä»…å½“å¤„äºæ‰‹åŠ¨æ¨¡å¼ï¼‰
    elif current_mode == MODE_MANUAL and cmd[0] in ('F','B','L','R','S') and len(cmd) > 1:
        send_command(cmd)
        print(f"æ‰‹åŠ¨æŒ‡ä»¤å·²å‘é€: {cmd}")
        last_manual_cmd_time = time.time()          # æ›´æ–°æœ€åæŒ‡ä»¤æ—¶é—´
        manual_timeout_alarm_triggered = False      # é‡ç½®è¶…æ—¶æŠ¥è­¦æ ‡å¿—
    # å…¶ä»–æœªçŸ¥æŒ‡ä»¤
    else:
        print(f"æœªçŸ¥æŒ‡ä»¤æˆ–æ¨¡å¼ä¸åŒ¹é…: {cmd}")

def read_bt_commands():
    """ç‹¬ç«‹çº¿ç¨‹ï¼šæŒç»­è¯»å–è“ç‰™ä¸²å£ï¼Œå°†æ”¶åˆ°çš„æŒ‡ä»¤æ”¾å…¥é˜Ÿåˆ—"""
    global bt_ser
    while True:
        # å¦‚æœè“ç‰™ä¸²å£æœªæ‰“å¼€æˆ–å·²æ–­å¼€ï¼Œå°è¯•é‡æ–°æ‰“å¼€
        if bt_ser is None or not bt_ser.is_open:
            try:
                bt_ser = serial.Serial(BT_SERIAL_PORT, BT_BAUDRATE, timeout=1)
                print("âœ… è“ç‰™ä¸²å£é‡æ–°è¿æ¥æˆåŠŸ")
            except Exception as e:
                # æ²¡æœ‰æ‰‹æœºè¿æ¥æ—¶æ­£å¸¸ï¼Œç­‰å¾…2ç§’åé‡è¯•
                time.sleep(2)
                continue

        try:
            # è¯»å–ä¸€è¡Œï¼ˆä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼‰
            line = bt_ser.readline().decode().strip()
            if line:
                bt_cmd_queue.put(line)
        except Exception as e:
            print(f"è“ç‰™è¯»å–é”™è¯¯: {e}ï¼Œå°è¯•é‡æ–°æ‰“å¼€ä¸²å£")
            try:
                bt_ser.close()
            except:
                pass
            bt_ser = None
            time.sleep(1)

def capture_frames():
    global current_frame, current_cmd_display, last_boxes, last_scores, all_boxes, all_scores
    global target_id, target_lost_frames, prev_target_box
    global current_mode, battery_voltage, ultrasonic_distance
    global manual_timeout_alarm_triggered, last_ultrasonic_alarm_time

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    cap.set(cv2.CAP_PROP_FPS, CAMERA_FPS)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, CAMERA_BUFFERSIZE)

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    # åº”ç”¨æ‘„åƒå¤´ä¼˜åŒ–å‚æ•°
    apply_camera_settings()
    time.sleep(0.5)

    print("ğŸš€ é‡‡é›†çº¿ç¨‹å¯åŠ¨ - ç»¼åˆä¼˜åŒ–ç‰ˆï¼ˆå¸¦è“ç‰™+æŠ¥è­¦ï¼‰")
    frame_count = 0
    frame_center_x = CAMERA_WIDTH // 2

    while True:
        current_time = time.time()

        # ---------- å¤„ç†è“ç‰™æŒ‡ä»¤ï¼ˆéé˜»å¡ï¼‰----------
        try:
            while True:  # ä¸€æ¬¡æ€§å¤„ç†é˜Ÿåˆ—ä¸­æ‰€æœ‰æŒ‡ä»¤
                cmd = bt_cmd_queue.get_nowait()
                process_bluetooth_command(cmd)
        except queue.Empty:
            pass

        # ---------- æ‘„åƒå¤´é‡‡é›† ----------
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue

        frame_count += 1

        # å›¾åƒå¢å¼ºï¼ˆå¯é€‰ï¼‰
        if ENABLE_ENHANCE:
            enhanced_frame = enhance_image(frame)
        else:
            enhanced_frame = frame

        # åŠ¨æ€æ¨ç†é—´éš”
        interval = FRAME_SKIP_IDLE if len(last_boxes) == 0 else FRAME_SKIP_TRACK
        do_inference = (frame_count % interval == 0)

        if do_inference:
            results = model.track(enhanced_frame,
                                  imgsz=INPUT_SIZE,
                                  conf=CONF_THRESH,
                                  iou=IOU_THRESH,
                                  classes=[0],
                                  persist=True,
                                  tracker=TRACKER_CFG,
                                  verbose=False)

            if results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes_xyxy = results[0].boxes.xyxy.cpu().numpy().astype(int)
                confs = results[0].boxes.conf.cpu().numpy()
                all_boxes = boxes_xyxy
                all_scores = confs

                if results[0].boxes.id is not None:
                    ids = results[0].boxes.id.cpu().numpy().astype(int)

                    if target_id is None:
                        target_id = select_target_from_boxes(boxes_xyxy, confs, ids, frame_center_x)
                        if target_id is not None:
                            print(f"ğŸ¯ é€‰å®šç›®æ ‡ ID: {target_id}")
                            target_lost_frames = 0
                            for i, tid in enumerate(ids):
                                if tid == target_id:
                                    last_boxes = np.array([boxes_xyxy[i]])
                                    last_scores = np.array([confs[i]])
                                    prev_target_box = last_boxes[0]
                                    break
                    else:
                        if target_id in ids:
                            target_lost_frames = 0
                            target_boxes = []
                            target_confs = []
                            for i, tid in enumerate(ids):
                                if tid == target_id:
                                    target_boxes.append(boxes_xyxy[i])
                                    target_confs.append(confs[i])
                            last_boxes = np.array(target_boxes)
                            last_scores = np.array(target_confs)
                            prev_target_box = last_boxes[0]
                        else:
                            target_lost_frames += 1
                            last_boxes = []
                            print(f"âš ï¸ ç›®æ ‡ä¸¢å¤±ï¼Œç´¯è®¡ {target_lost_frames}/{MAX_MISSED_FRAMES}")
                            if target_lost_frames > MAX_MISSED_FRAMES:
                                new_id = select_target_from_boxes(boxes_xyxy, confs, ids, frame_center_x)
                                if new_id is not None:
                                    target_id = new_id
                                    print(f"ğŸ”„ ç›®æ ‡è¶…æ—¶ï¼Œé‡æ–°é€‰å®šç›®æ ‡ ID: {target_id}")
                                    target_lost_frames = 0
                                    for i, tid in enumerate(ids):
                                        if tid == target_id:
                                            last_boxes = np.array([boxes_xyxy[i]])
                                            last_scores = np.array([confs[i]])
                                            prev_target_box = last_boxes[0]
                                            break
                                else:
                                    target_id = None
                                    last_boxes = []
                                    last_scores = []
                                    prev_target_box = None
                else:
                    last_boxes = boxes_xyxy
                    last_scores = confs
                    target_id = None
                    prev_target_box = None
            else:
                all_boxes = []
                all_scores = []
                if target_id is not None:
                    target_lost_frames += 1
                    last_boxes = []
                    if target_lost_frames > MAX_MISSED_FRAMES:
                        print("ğŸ”„ ç›®æ ‡å®Œå…¨æ¶ˆå¤±ï¼Œé‡ç½®")
                        target_id = None
                        target_lost_frames = 0
                        last_boxes = []
                        last_scores = []
                        prev_target_box = None
                else:
                    last_boxes = []
                    last_scores = []

        # ---------- æ ¹æ®æ¨¡å¼è®¡ç®—æŒ‡ä»¤ ----------
        if current_mode == MODE_AUTO:
            if target_id is not None and len(last_boxes) > 0:
                cmd_boxes = last_boxes
            else:
                cmd_boxes = []   # æ— äººæˆ–ç›®æ ‡ä¸¢å¤±ï¼Œåœæ­¢
            cmd, value = calculate_command(cmd_boxes, frame_center_x)
            if cmd == 'F':
                cmd_str = f"F{value}"
            elif cmd in ('L', 'R'):
                cmd_str = f"{cmd}{value}"
            else:
                cmd_str = "S"
            send_command(cmd_str)
            current_cmd_display = cmd_str
        else:
            # æ‰‹åŠ¨æ¨¡å¼ä¸‹ï¼Œä¸è‡ªåŠ¨å‘é€æŒ‡ä»¤ï¼Œåªæ˜¾ç¤ºâ€œMANUALâ€
            current_cmd_display = "MANUAL"

        # ---------- è¯»å–ä¸‹ä½æœºä¸²å£ï¼ˆç”µé‡ã€è¶…å£°æ³¢ç­‰ä¿¡æ¯ï¼‰----------
        if ser and ser.is_open:
            try:
                while ser.in_waiting:
                    line = ser.readline().decode().strip()
                    if line.startswith("VOLT:"):
                        battery_voltage = float(line[5:])
                    elif line.startswith("US:"):
                        try:
                            ultrasonic_distance = float(line[3:])
                        except:
                            pass
            except Exception as e:
                # å¿½ç•¥è¯»å–é”™è¯¯
                pass

        # ---------- æŠ¥è­¦æ£€æŸ¥ ----------
        # 1. æ‰‹åŠ¨æ¨¡å¼è¶…æ—¶æŠ¥è­¦
        if current_mode == MODE_MANUAL:
            if (current_time - last_manual_cmd_time) > MANUAL_TIMEOUT_SEC and not manual_timeout_alarm_triggered:
                send_bt_response("ALARM: MANUAL_TIMEOUT")
                manual_timeout_alarm_triggered = True
                print("âš ï¸ æŠ¥è­¦ï¼šæ‰‹åŠ¨æ¨¡å¼è¶…æ—¶ï¼Œåˆ‡æ¢è‡³è‡ªåŠ¨æ¨¡å¼")
                # å¯é€‰ï¼šè‡ªåŠ¨åˆ‡å›è‡ªåŠ¨æ¨¡å¼ï¼ˆè¿™é‡Œå®ç°åˆ‡æ¢ï¼‰
                current_mode = MODE_AUTO
        else:
            manual_timeout_alarm_triggered = False  # ä¸åœ¨æ‰‹åŠ¨æ¨¡å¼æ—¶é‡ç½®

        # 2. è¶…å£°æ³¢æ¥è¿‘æŠ¥è­¦
        if ultrasonic_distance is not None and ultrasonic_distance < ULTRASONIC_ALARM_DISTANCE:
            if (current_time - last_ultrasonic_alarm_time) > ULTRASONIC_ALARM_COOLDOWN:
                send_bt_response(f"ALARM: OBSTACLE {int(ultrasonic_distance)}cm")
                last_ultrasonic_alarm_time = current_time
                print(f"âš ï¸ æŠ¥è­¦ï¼šéšœç¢ç‰© {int(ultrasonic_distance)}cm")

        # ---------- ç»˜åˆ¶ç”»é¢ ----------
        annotated = frame.copy()

        # ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹æ¡†ï¼ˆç»¿è‰²ï¼‰
        if len(all_boxes) > 0:
            for box, score in zip(all_boxes, all_scores):
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,255,0), 2)
                cv2.putText(annotated, f"person: {score:.2f}", (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
            cv2.putText(annotated, f"Total: {len(all_boxes)}", (10,30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,0), 2)

        # ç»˜åˆ¶å½“å‰ç›®æ ‡ï¼ˆçº¢è‰²å®çº¿æ¡†ï¼‰
        if target_id is not None and len(last_boxes) > 0:
            for box in last_boxes:
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,0,255), 3)
                cv2.putText(annotated, f"Target ID: {target_id}", (x1, y1-30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)

        if len(all_boxes) == 0:
            cv2.putText(annotated, "No person detected", (10,30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)

        # æ˜¾ç¤ºå½“å‰æ¨¡å¼ã€ç”µé‡ã€è¶…å£°æ³¢è·ç¦»
        mode_text = "AUTO" if current_mode == MODE_AUTO else "MANUAL"
        volt_text = f"{battery_voltage:.1f}V" if battery_voltage else "N/A"
        us_text = f"{int(ultrasonic_distance)}cm" if ultrasonic_distance else "N/A"
        cv2.putText(annotated, f"Mode: {mode_text}", (10, 100),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)
        cv2.putText(annotated, f"Batt: {volt_text}", (10, 130),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)
        cv2.putText(annotated, f"US: {us_text}", (10, 160),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)

        cv2.putText(annotated, f"Cmd: {current_cmd_display}", (10,70),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)

        with frame_lock:
            current_frame = annotated

        time.sleep(0.01)

    cap.release()
    if ser:
        ser.close()
    if bt_ser:
        bt_ser.close()

def generate_frames():
    while True:
        with frame_lock:
            if current_frame is None:
                continue
            ret, jpeg = cv2.imencode('.jpg', current_frame, [cv2.IMWRITE_JPEG_QUALITY, JPEG_QUALITY])
            if not ret:
                continue
            frame_bytes = jpeg.tobytes()
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        time.sleep(STREAM_SLEEP)

@app.route('/')
def index():
    # åŠ¨æ€ç”Ÿæˆ HTMLï¼Œæ˜¾ç¤ºå½“å‰æ¨¡å¼å’Œç”µé‡ã€è¶…å£°æ³¢
    mode_str = "è‡ªåŠ¨" if current_mode == MODE_AUTO else "æ‰‹åŠ¨"
    volt_str = f"{battery_voltage:.1f}V" if battery_voltage else "æœªçŸ¥"
    us_str = f"{int(ultrasonic_distance)}cm" if ultrasonic_distance else "æœªçŸ¥"
    html = f'''
    <!DOCTYPE html>
    <html>
    <head><title>æ ‘è“æ´¾æ™ºèƒ½è·Ÿéš - è“ç‰™æ§åˆ¶ç‰ˆï¼ˆå¸¦æŠ¥è­¦ï¼‰</title></head>
    <body>
        <h1>YOLOv8 å¤šç›®æ ‡ç¨³å®šè·Ÿè¸ª + è“ç‰™æ‰‹æœºæ§åˆ¶ + æŠ¥è­¦</h1>
        <img src="/video_feed" style="max-width:100%">
        <p>å½“å‰æŒ‡ä»¤: {current_cmd_display}</p>
        <p>å½“å‰æ¨¡å¼: {mode_str}</p>
        <p>è¶…å£°æ³¢è·ç¦»: {us_str}</p>
        <p>ç»¿è‰²æ¡†ä¸ºæ‰€æœ‰æ£€æµ‹åˆ°çš„äººï¼Œçº¢è‰²å®çº¿æ¡†ä¸ºå½“å‰ç›®æ ‡</p>
        <hr>
        <p><b>è“ç‰™æŒ‡ä»¤è¯´æ˜ï¼š</b></p>
        <ul>
            <li><code>MODE_AUTO</code> - åˆ‡æ¢ä¸ºè‡ªåŠ¨è·Ÿéšæ¨¡å¼</li>
            <li><code>MODE_MANUAL</code> - åˆ‡æ¢ä¸ºæ‰‹åŠ¨æ§åˆ¶æ¨¡å¼</li>
            <li><code>F200</code> / <code>L50</code> / <code>R80</code> / <code>S</code> - æ‰‹åŠ¨æ¨¡å¼ä¸‹ç›´æ¥æ§åˆ¶å°è½¦</li>
        </ul>
        <p><b>æŠ¥è­¦æ¶ˆæ¯ï¼ˆé€šè¿‡è“ç‰™æ¥æ”¶ï¼‰ï¼š</b></p>
        <ul>
            <li><code>ALARM: MANUAL_TIMEOUT</code> - æ‰‹åŠ¨æ¨¡å¼è¶…æ—¶ï¼ˆ{MANUAL_TIMEOUT_SEC}ç§’æ— æŒ‡ä»¤ï¼‰</li>
            <li><code>ALARM: OBSTACLE xxxcm</code> - è¶…å£°æ³¢æ£€æµ‹åˆ°éšœç¢ç‰©è·ç¦»ä½äº {ULTRASONIC_ALARM_DISTANCE}cm</li>
        </ul>
    </body>
    </html>
    '''
    return render_template_string(html)

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    # å¯åŠ¨è“ç‰™è¯»å–çº¿ç¨‹
    bt_thread = threading.Thread(target=read_bt_commands, daemon=True)
    bt_thread.start()

    # å¯åŠ¨æ‘„åƒå¤´é‡‡é›†çº¿ç¨‹
    t = threading.Thread(target=capture_frames, daemon=True)
    t.start()

    print("="*60)
    print("æœåŠ¡å¯åŠ¨æˆåŠŸï¼è®¿é—® http://<æ ‘è“æ´¾IP>:5000")
    print("æ¨¡å‹è·¯å¾„:", MODEL_PATH)
    if 'TRACKER_CFG' in dir():
        print("è·Ÿè¸ªå™¨é…ç½®:", TRACKER_CFG)
    print("æ‘„åƒå¤´ä¼˜åŒ–å‚æ•°å·²å¯ç”¨ï¼Œå›¾åƒå¢å¼º:", ENABLE_ENHANCE)
    print("ç›®æ ‡ä¸¢å¤±ç«‹å³åœæ­¢ï¼Œæ— è™šçº¿æ¡†")
    print("è“ç‰™æ§åˆ¶å·²å¯ç”¨ï¼ˆéœ€ç¡®ä¿ç³»ç»Ÿå·²è¿è¡Œ rfcomm listener æœåŠ¡ï¼‰")
    print("æŠ¥è­¦åŠŸèƒ½ï¼šæ‰‹åŠ¨è¶…æ—¶ + è¶…å£°æ³¢é¿éšœ")
    print("="*60)
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)